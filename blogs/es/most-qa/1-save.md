---
title: 数据可靠性
---

可靠性来源于数据的同步。

## 内存与磁盘的同步

和 WALL、BinLog... 一样，ES也有自己保证数据可靠性的日志文件 **transLog**，先来理解为什么要推出这个日志文件。  

已知ES的持久化是要将数据存入磁盘，为了高效地进行读写操作，每次进行读写（不仅仅是一读次写请求，也可能是一次底层系统调用）时都往对应磁盘位置 “随机写” 或者 “随机读” 是很慢的，那就要考虑通过内存进行过渡。  
但使用内存的话可能会导致断电时数据丢失，因此添加一个 “顺序写” 的日志文件进行记录，因此每次写操作会将数据双写入内存和transLog。  

::: tip

可配的两种写transLog策略，`index.translog.durability` 的支持参数：
- request: （默认）同步写，较为可靠
- async: 异步写，可能会造成数据丢失

:::

而为了transLog内的数据不会无限增长，当transLog过大(调整index.translog.flush_threshold_size，默认512mb)或者达到30分钟时，会执行一次 flush 操作，会将 es 的数据从内存持久化到磁盘，同时进行 transLog 的删除。
其实es存储到内存中数据的下一个目的地并不直接是磁盘，而是以段的形式提交到文件缓存系统，这个行为叫做 refresh，这是在 flush 之前的行为，一秒左右执行一次，为了让段数不会太多而降低性能，ES会对符合条件的段进行合并。  

## 节点与节点的同步

这个在前面介绍 [分片](../group/0-shards.html#分片) 的时候也介绍过，其实 ES 的集群是以分布式为基础的，每个节点都被分配了索引创建时定好的分片的一部分。  
它的 “数据一致性” 更多地体现在主副本分片上，也是前面说的那一套，主分片修改时副本分片同步复制，主分片挂掉时一个副本分片升级为主分片。  